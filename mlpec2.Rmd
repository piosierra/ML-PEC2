---
title: "PEC2- ML"
author: "Pío Alberto Sierra Rodríguez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_document:
    df_print: paged
    toc: yes
  pdf_document:
    toc: yes
params:
  data_file: peptidos.csv
  training_split: 67
  seed.split: 123
  seed.clsfier: 1234567
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE}
if(!(require(ggseqlogo)))
  install.packages("ggseqlogo")
if(!(require(caret)))
  install.packages("caret")
if(!(require(e1071)))
  install.packages("e1071")
if(!(require(neuralnet)))
  install.packages("NeuralNetTools)")
if(!(require(NeuralNetTools)))
  install.packages("NeuralNetTools")
if(!(require(kernlab)))
  install.packages("kernlab")
if(!(require(class)))
  install.packages("class")
if(!(require(gmodels)))
  install.packages("gmodels")
if(!(require(ROCR)))
  install.packages("ROCR")
if(!(require(caret)))
  install.packages("caret")
if(!(require(e1071)))
  install.packages("e1071")
if(!(require(RSNNS)))
  install.packages("RSNNS")
```

***  
**Parámetros:**  
**data_file**: *ruta completa al archivo de péptidos*  
**training_splt**: *porcentaje a dedicar al conjunto de training [0,100]*
*** 

# Algoritmo Red Neuronal Artificial

El algoritmo de Red Neuronal Artificial con retropropagación está inspirado en el funcionamiento de las redes neuronales biológicas, pero con un menor número de neuronas y capas. Funciona iterando repetidamente dos procesos. En uno se obtiene una salida y en otro se propaga el error de esa salida hacia atrás para corregir los pesos de de cada neurona, mediante la técnica de gradiente descendente.

Fortalezas | Debilidades
-----|------
Se puede adaptar a problemas de clasificación o predicción numéricos  | Muy costosa computacionalmente y lenta durante el aprendizaje, especialmente si la topología de la red es compleja.  
Capaz de modelizar estructuras más complejas que la mayoría de algoritmos | Es fácil caer en problemas de overfitting con esta técnica.  
Hace pocas presunciones sobre las relaciones internas de los datos | El resultado en un modelo de caja negra que es muy difícil, si no imposible, de interpretar. 

# Algoritmo Support Vector Machine

El algoritmo SVN consiste en la creacción de hiperplanos en el espacio definido por los valores de las características que creen particiones en las que clasificar los datos.  

Ventajas| Inconvenientes
-----|------
Pueden ser usados tanto para clasificación como para predicción numérica | Encontrar el mejor modelo exige probar con distintos kernels y parámetros.  
No se ve muy afectado por ruido en los datos ni es susceptible de sobreajuste. | El entrenamiento puede ser lento, sobre todo cuando se trata de datos con un gran número de características u observaciones.  
Puede resultar más sencillo de utilizar que las redes neuronales, debido a la existencia de varios algoritmos de SVN bien mantenidos. | El resultado es un complejo modelo de caja negra que resulta a menudo imposible de interpretar.  
Es bastante popular debido a su precisión y al haber resultado vencedor en varias competiciones de data mining. | -  

El algoritmo consiste en identificar los Support Vectors, las observaciones de cada clase que están más cerca del Hyperplano de margen máximo (MMH). Se demuestra que estos puntos bastan para definir el hiperplano. Para el caso de datos que no son linealmente separables, se utiliza una variable slack que define un margen al otro lado del hiperplano al que es aceptable tener alguna observación.  

Otra ventaja de SVN es la posiblidad de añadir más dimensiones a las observaciones para así hacer visibles (lineales) relaciones entre las observaciones.  

# Lectura de datos

```{r}
peptidos <- read.csv2(params$data_file)
table(peptidos$label)
ggseqlogo(peptidos[which(peptidos$label=="SB"),]$sequence)
ggseqlogo(peptidos[which(peptidos$label=="NB"),]$sequence)
```

Tenemos un `r 100*sum(peptidos$label=="SB")/length(peptidos$label)`% de peptidos con interacción.  

Podemos observar que los péptidos que tienen interacción presentan una mayor frecuencia muy marcada de aminoácidos hidrófobos en la segunda y última posición de la cadena.  

# Codificación "one-hot"

```{r}
aminoacidos <-c('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y')
one_hot <- function(data) {
    unlist(lapply(strsplit(data, split="")[[1]], 
                  function(x) {as.integer(aminoacidos == x)}), 
           recursive = FALSE)
}
oh_data <- data.frame(t(data.frame(lapply(peptidos$sequence, one_hot))))
rownames(oh_data) <- peptidos$sequence  
```

# Clasificador de red neuronal artificial

## Preparación de datos  

Creamos variables binarias en lugar de usar la variable factor `label`.   
```{r}
oh_data$SB <- as.integer(peptidos$label=="SB")
oh_data$NB <- as.integer(peptidos$label=="NB")
n <- nrow(oh_data)
```

Ahora creamos los conjuntos entrenamiento y de prueba. Se realiza una extracción de los datos *aleatoriamente* de `r params$training_split`% de todas las observaciones, `r floor(params$training_split*n/100)`, para entrenar al modelo (training) y del resto `r n - floor(params$training_split*n/100)` para evaluarlo (test).
```{r}
set.seed(params$seed.split)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- oh_data[train_ind,]
data_test <- oh_data[-train_ind,]
```

## Entrenamiendo de modelo de 1 nodo y de modelo de 3 nodos

```{r}
xnam <- names(oh_data[1:180])
fmla <- as.formula(paste("SB+NB ~ ", paste(xnam, collapse= "+")))
set.seed(params$seed.clsfier)
data_model_1 <- neuralnet(fmla,
                          data = data_train,
                          hidden=1,linear.output=FALSE)
set.seed(params$seed.clsfier)
data_model_3 <- neuralnet(fmla,
                          data = data_train,
                          hidden=3,linear.output=FALSE)
plot(data_model_1, rep='best')
plot(data_model_3, rep='best')

```

Obtenemos las predicciones y convertimos la salida numérica binaria (probabilidades) en una categórica para comparar los resultados.

```{r}

model_results_1 <- compute(data_model_1, data_test[,1:180])$net.result
model_results_3 <- compute(data_model_3, data_test[,1:180])$net.result

maxidx <- function(arr) {
  return(which(arr == max(arr)))
}

idx1 <- apply(model_results_1, 1, maxidx)
idx3 <- apply(model_results_3, 1, maxidx)
prediction1 <- c('SB', 'NB')[idx1]
prediction3 <- c('SB', 'NB')[idx3]
res1 <- table(prediction1, peptidos$label[-train_ind] )
res3 <- table(prediction3, peptidos$label[-train_ind] )

(cmatrix1 <- caret::confusionMatrix(res1,positive="SB"))
(cmatrix3 <- caret::confusionMatrix(res3,positive="SB"))
```

El modelo de una capa con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix1$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix1$byClass["Sensitivity"], 3)` y `r round(cmatrix1$byClass["Specificity"], 3)` respectivamente.  
El modelo de tres capas con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix3$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix3$byClass["Sensitivity"], 3)` y `r round(cmatrix3$byClass["Specificity"], 3)` respectivamente.  
`r if(cmatrix1$overall["Accuracy"] > cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con un solo nodo tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] < cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con tres nodos tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] == cmatrix3$overall["Accuracy"]){"Vemos que ambos modelos tienen la misma precisión"}`

```{r}

mlp3 <- mlp(data_train[,1:180], data_train[,181:182], size=3, learnFuncParams=c(0.1), 
              maxit=50, inputsTest=data_test[,1:180], targetsTest=data_test[,181:182])
model_results <- predict(mlp3,data_test[,1:180])
idx <- apply(model_results, 1, maxidx)
prediction <- c('SB', 'NB')[idx]
res <- table(prediction, peptidos$label[-train_ind])
(cmatrix <- caret::confusionMatrix(res,positive="SB"))
```
```{r}
# model <- train(data_train[,1:180], as.factor(peptidos$label[train_ind]), method='mlp', 
#                trControl= trainControl(method='cv', number=5), 
#                tuneGrid= NULL, tuneLength=10 ,trace = FALSE)
# 
# plotnet(model, alpha=0.6)
# summary(model)
# prediction <- predict(model, test.set[-10])                           # predict
# table(prediction, test.set$Class)  
```

# Clasificador de SVN

## Preparación de datos  

Para SVN vamos a utilizar como resultado la variable `label` original, sin necesidad de convertirla a un valor numérico como hicimos para la red neuronal.


```{r}
set.seed(params$seed.split)
data_svn <- oh_data[,1:180]
data_svn$label <- as.factor(peptidos$label)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- data_svn[train_ind,]
data_test <- data_svn[-train_ind,]
```


```{r}
set.seed(params$seed.clsfier)
(modeloLineal <- ksvm(label~.,data=data_train, kernel='vanilladot'))

modLineal_pred <- predict(modeloLineal, data_test)

res <- table(modLineal_pred, data_test$label)
(cmatrix1 <- caret::confusionMatrix(res, positive="SB"))
```
```{r}
set.seed(params$seed.clsfier)
(modeloGauss <- ksvm(label~.,data=data_train, kernel='rbfdot'))

modGauss_pred <- predict(modeloGauss, data_test)

res <- table(modGauss_pred, data_test$label)
(cmatrix1 <- caret::confusionMatrix(res, positive="SB"))
```
