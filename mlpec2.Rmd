---
title: "Predicción de interacción entre péptido y el complejo mayor de histocompatibilidad tipo I con Artificial Neural Networks (ANN) y Support Vector Machines (SVM)"
author: "Pío Alberto Sierra Rodríguez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
params:
  data_file: peptidos.csv
  training_split: 67
  seed.split: 123
  seed.clsfier: 1234567
  transformed_file: peptidos_transf_one_hot.csv
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE, fig.height=3.5) 
```

```{r include = FALSE}
if(!(require(ggseqlogo)))
  install.packages("ggseqlogo")
if(!(require(caret)))
  install.packages("caret")
if(!(require(e1071)))
  install.packages("e1071")
if(!(require(neuralnet)))
  install.packages("NeuralNetTools)")
if(!(require(NeuralNetTools)))
  install.packages("NeuralNetTools")
if(!(require(kernlab)))
  install.packages("kernlab")
if(!(require(class)))
  install.packages("class")
if(!(require(gmodels)))
  install.packages("gmodels")
if(!(require(ROCR)))
  install.packages("ROCR")
if(!(require(e1071)))
  install.packages("e1071")
```

***   

**Parámetros modificables en Knit:**  
**data_file**: *ruta completa al archivo de péptidos*  
**training_splt**: *porcentaje a dedicar al conjunto de training [0,100]*  
**seed.split**: *semilla para la división de los datos en conjunto y entrenamiento.*  
**seed.clsfier**: *semilla para la ejecución de cada modelo.*  
**transformed_file**: *archivo en el que almacenar lod datos transformados con la codificación one-hot.*  

***  

# 1- Algoritmos utilizados

## Algoritmo Red Neuronal Artificial

El algoritmo de Red Neuronal Artificial con retropropagación está inspirado en el funcionamiento de las redes neuronales biológicas, pero con un menor número de neuronas y capas. Funciona iterando repetidamente dos procesos. En uno se obtiene una salida y en otro se propaga el error de esa salida hacia atrás para corregir los pesos de de cada neurona, mediante la técnica de gradiente descendente.

Fortalezas | Debilidades
-----|------
Se puede adaptar a problemas de clasificación o predicción numéricos  | Muy costosa computacionalmente y lenta durante el aprendizaje, especialmente si la topología de la red es compleja.  
Capaz de modelizar estructuras más complejas que la mayoría de algoritmos | Es fácil caer en problemas de overfitting con esta técnica.  
Hace pocas presunciones sobre las relaciones internas de los datos | El resultado en un modelo de caja negra que es muy difícil, si no imposible, de interpretar. 

## Algoritmo Support Vector Machine

El algoritmo SVN consiste en la creacción de hiperplanos en el espacio definido por los valores de las características que creen particiones en las que clasificar los datos.  

Ventajas| Inconvenientes
-----|------
Pueden ser usados tanto para clasificación como para predicción numérica | Encontrar el mejor modelo exige probar con distintos kernels y parámetros.  
No se ve muy afectado por ruido en los datos ni es susceptible de sobreajuste. | El entrenamiento puede ser lento, sobre todo cuando se trata de datos con un gran número de características u observaciones.  
Puede resultar más sencillo de utilizar que las redes neuronales, debido a la existencia de varios algoritmos de SVN bien mantenidos. | El resultado es un complejo modelo de caja negra que resulta a menudo imposible de interpretar.  
Es bastante popular debido a su precisión y al haber resultado vencedor en varias competiciones de data mining. | -  

El algoritmo consiste en identificar los Support Vectors, las observaciones de cada clase que están más cerca del Hyperplano de margen máximo (MMH). Se demuestra que estos puntos bastan para definir el hiperplano. Para el caso de datos que no son linealmente separables, se utiliza una variable slack que define un margen al otro lado del hiperplano al que es aceptable tener alguna observación.  

Otra ventaja de SVN es la posiblidad de añadir más dimensiones a las observaciones para así hacer visibles (lineales) relaciones entre las observaciones.  

# 2 - Lectura de datos

Leemos los datos del archivo con los péptidos.  
```{r}
peptidos <- read.csv2(params$data_file)
```
Comprobamos la relación entre péptidos de uno y otro tipo.  
```{r}
table(peptidos$label)
```
Tenemos un `r 100*sum(peptidos$label=="SB")/length(peptidos$label)`% de peptidos con interacción.   

Mostramos la composición de aminoácidos para cada tipo de péptido.  

```{r}
ggseqlogo(peptidos[which(peptidos$label=="SB"),]$sequence)
ggseqlogo(peptidos[which(peptidos$label=="NB"),]$sequence)
```

Podemos observar que los péptidos que tienen interacción presentan una mayor frecuencia muy marcada de aminoácidos hidrófobos en la segunda y última posición de la cadena.  

# 3 - Función de codificación "one-hot"

Implementamos una función que cree la codificación "one-hot" a partir de una cadena de aminoácidos. Basta con tomar los ceros y unos de hacer una comparación directa con una cadena de todos los aminoácidos.    
```{r}
aminoacidos <-c('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y')
one_hot <- function(data) {
    unlist(lapply(strsplit(data, split="")[[1]], 
                  function(x) {as.integer(aminoacidos == x)}), 
           recursive = FALSE)
}
```

# 4 - Transformación de los datos

Aplicamos ahora esa función a la lista de aminoácidos de la entrada para obtener los datos que vamos a utilizar.  
```{r}
oh_data <- data.frame(t(data.frame(lapply(peptidos$sequence, one_hot))))
```
Comprobamos que la transformación deja correctamente `r nchar(peptidos[1,1])` unos en cada fila. Y guardamos los datos.
```{r}
summary(apply(oh_data,1,sum))
write.table(oh_data, params$transformed_file, row.names = FALSE, sep = ";")
```


# 5 - Clasificador de red neuronal artificial

## Paso 1 - Lectura de los datos

Leemos los datos del archivo `r params$transformed_file`. 
```{r}
oh_data <- read.csv2(params$transformed_file)
```

## Paso 2 - Exploración y preparación de datos  

Comprobamos de nuevo que la transformación deja correctamente `r nchar(peptidos[1,1])` unos en cada fila (uno por cada aminoácido en la cadena).  
```{r}
summary(apply(oh_data,1,sum))
```

`r if(sum(complete.cases(oh_data)) == nrow(oh_data)){"Comprobamos que no hay observaciones con datos faltantes."}``r if(sum(complete.cases(oh_data)) != nrow(oh_data)){paste("El archivo de datos tiene",nrow(oh_data)- sum(complete.cases(oh_data)), "observaciones en las que faltan datos", sep=" ")}`

Creamos variables binarias en lugar de usar la variable factor `label`. Almacenamos en una variable `n` el número de observaciones.
```{r}
oh_data$SB <- as.integer(peptidos$label=="SB")
oh_data$NB <- as.integer(peptidos$label=="NB")
n <- nrow(oh_data)
```

Ahora creamos los conjuntos entrenamiento y de prueba. Se realiza una extracción de los datos *aleatoriamente* de `r params$training_split`% de todas las observaciones, `r floor(params$training_split*n/100)`, para entrenar al modelo (training) y del resto `r n - floor(params$training_split*n/100)` para evaluarlo (test).
```{r}
set.seed(params$seed.split)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- oh_data[train_ind,]
data_test <- oh_data[-train_ind,]
```

## Paso 3 - Entrenamiento y predicción del modelo RNA de 1 nodo y del modelo RNA de 3 nodos

Primero creamos la fórmula a partir de los nombres de las columnas.
```{r}
xnam <- names(oh_data[1:180])
fmla <- as.formula(paste("SB+NB ~ ", paste(xnam, collapse= "+")))
```
Creamos los modelos reseteando la semilla antes de cada uno al valor `params$seed.clsfier`.  
```{r}
# Modelo RNA con 1 nodo
set.seed(params$seed.clsfier)
data_model_1 <- neuralnet(fmla,
                          data = data_train,
                          hidden=1,linear.output=FALSE)

# Modelo RNA con 3 nodos
set.seed(params$seed.clsfier)
data_model_3 <- neuralnet(fmla,
                          data = data_train,
                          hidden=3,linear.output=FALSE)

```

Mostramos las redes resultantes de cada modelo.  

```{r}
plot(data_model_1, rep='best')
plot(data_model_3, rep='best')

```

Obtenemos las predicciones y convertimos la salida numérica binaria (probabilidades) en una categórica para comparar los resultados.

```{r}

model_results_1 <- compute(data_model_1, data_test[,1:180])$net.result
model_results_3 <- compute(data_model_3, data_test[,1:180])$net.result

maxidx <- function(arr) {
  return(which(arr == max(arr)))
}

idx1 <- apply(model_results_1, 1, maxidx)
idx3 <- apply(model_results_3, 1, maxidx)
prediction1 <- c('SB', 'NB')[idx1]
prediction3 <- c('SB', 'NB')[idx3]


```

## Paso 4 - Evaluación del rendimiento del modelo.

```{r}
res1 <- table(prediction1, peptidos$label[-train_ind] )
res3 <- table(prediction3, peptidos$label[-train_ind] )
(cmatrix1 <- caret::confusionMatrix(res1,positive="SB"))
(cmatrix3 <- caret::confusionMatrix(res3,positive="SB"))
```

El modelo de una capa con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix1$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix1$byClass["Sensitivity"], 3)` y `r round(cmatrix1$byClass["Specificity"], 3)` respectivamente.  
El modelo de tres capas con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix3$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix3$byClass["Sensitivity"], 3)` y `r round(cmatrix3$byClass["Specificity"], 3)` respectivamente.  
`r if(cmatrix1$overall["Accuracy"] > cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con un solo nodo tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] < cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con tres nodos tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] == cmatrix3$overall["Accuracy"]){"Vemos que ambos modelos tienen la misma precisión"}`

## Paso 5 - Mejora del rendimiento del modelo: Modelo `mlp` de 3 nodos con 5-fold crossvalidation.

Ahora utilizamos el paquete `caret` para entrenar un modelo Multi-Layer Perceptron. Para detallar que es de tres nodos tenemos que incluir un data.frame en la variable `tuneGrid` de `train` con los parámetros necesarios para el modelo, en este caso `size`, como columnas con el nombre del parámetro empezando por ".".  

```{r}
set.seed(params$seed.clsfier)
data.frame(.size=3)
model <- caret::train(data_train[,1:180], as.factor(peptidos$label[train_ind]), 
                      method='mlp', trControl= trainControl(method='cv', number=5), 
                      tuneGrid= data.frame(.size=3), tuneLength=10 ,trace = FALSE)
prediction <- predict(model, data_test) 
res <- table(prediction, peptidos$label[-train_ind] )
(cmatrix_mlp <- caret::confusionMatrix(res,positive="SB"))
```

El modelo `mlp` de tres capas con categoria positiva 'SB' usando 5-fold crossvalidation obtiene una precisión de `r round(cmatrix_mlp$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_mlp$byClass["Sensitivity"], 3)` y `r round(cmatrix_mlp$byClass["Specificity"], 3)` respectivamente.  

# 6 - Implementación de un clasificador de SVN

## Paso 1 - Lectura de los datos

Leemos los datos del archivo `r params$transformed_file`.   
```{r}
oh_data <- read.csv2(params$transformed_file)
```

## Paso 2 - Exploración y preparación de datos  

Comprobamos de nuevo que la transformación deja correctamente `r nchar(peptidos[1,1])` unos en cada fila (uno por cada aminoácido en la cadena).  
```{r}
summary(apply(oh_data,1,sum))
```

`r if(sum(complete.cases(oh_data)) == nrow(oh_data)){"Comprobamos que no hay observaciones con datos faltantes."}``r if(sum(complete.cases(oh_data)) != nrow(oh_data)){paste("El archivo de datos tiene",nrow(oh_data)- sum(complete.cases(oh_data)), "observaciones en las que faltan datos", sep=" ")}`

Para SVN vamos a utilizar como resultado la variable `label` original, sin necesidad de convertirla a un valor numérico como hicimos para la red neuronal.  

Ahora creamos los conjuntos entrenamiento y de prueba. Se realiza una extracción de los datos *aleatoriamente* de `r params$training_split`% de todas las observaciones, `r floor(params$training_split*n/100)`, para entrenar al modelo (training) y del resto `r n - floor(params$training_split*n/100)` para evaluarlo (test).

```{r}
set.seed(params$seed.split)
data_svn <- oh_data[,1:180]
data_svn$label <- as.factor(peptidos$label)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- data_svn[train_ind,]
data_test <- data_svn[-train_ind,]
```
## Paso 3 - Entrenamiento y predicción de modelos SVN lineal y SVN RBF  

Creamos los modelos reseteando la semilla antes de cada uno al valor `params$seed.clsfier`.  También obtenemos la predicción para los datos de prueba.  

```{r}
# Modelo lineal
set.seed(params$seed.clsfier)
(modeloLineal <- ksvm(label~.,data=data_train, kernel='vanilladot'))
modLineal_pred <- predict(modeloLineal, data_test)

# Modelo RBF
set.seed(params$seed.clsfier)
(modeloGauss <- ksvm(label~.,data=data_train, kernel='rbfdot'))
modGauss_pred <- predict(modeloGauss, data_test)

```


## Paso 4 - Evaluación del rendimiento del modelo.

```{r}
res_lineal <- table(modLineal_pred, data_test$label)
res_rbf <- table(modGauss_pred, data_test$label)
(cmatrix_lineal <- caret::confusionMatrix(res_lineal, positive="SB"))
(cmatrix_rbf <- caret::confusionMatrix(res_rbf, positive="SB"))
```

El modelo SVN lineal con categoría positiva 'SB' obtiene una precisión de `r round(cmatrix_lineal$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_lineal$byClass["Sensitivity"], 3)` y `r round(cmatrix_lineal$byClass["Specificity"], 3)` respectivamente.  

El modelo SVN RBF con categoría positiva 'SB' obtiene una precisión de `r round(cmatrix_rbf$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_rbf$byClass["Sensitivity"], 3)` y `r round(cmatrix_rbf$byClass["Specificity"], 3)` respectivamente.  

`r if(cmatrix_lineal$overall["Accuracy"] > cmatrix_rbf$overall["Accuracy"]){"Vemos que el modelo SVN lineal tiene una mayor precisión"}``r if(cmatrix_lineal$overall["Accuracy"] < cmatrix_rbf$overall["Accuracy"]){"Vemos que el modelo SVN RBF tiene una mayor precisión"}``r if(cmatrix_lineal$overall["Accuracy"] == cmatrix_rbf$overall["Accuracy"]){"Vemos que ambos modelos tienen la misma precisión"}`

## Paso 5 - Mejora del rendimiento del modelo: Modelo SVN RBF del paquete `caret` con 5-fold crossvalidation.

Ahora utilizamos el paquete `caret` para entrenar un modelo SVN con el método `svmRadial`. Para detallar que es de tres nodos tenemos que incluir un data.frame en la variable `tuneGrid` de `train` con los parámetros necesarios para el modelo, en este caso `sigma` y `C`, como columnas con el nombre del parámetro empezando por ".".  
En este caso optamos por probar con varias combinaciones de los parámetros y escoger la mejor en función de la precisión.  


```{r}
svmGrid <- expand.grid(sigma= 2^c(-10,-8), C= 2^c(0,1))
set.seed(params$seed.clsfier)
model <- caret::train(label~., data= data_train, method='svmRadial', 
               trControl= trainControl(method='cv', number=5, classProbs = TRUE), 
                tuneGrid= svmGrid, metric = "Accuracy",trace = FALSE)
model
prediction <- predict(model, data_test)                
res <- table(prediction, data_test$label)                      

(cmatrix_rbf5f <- caret::confusionMatrix(res, positive="SB"))

```
El modelo `mlp` de tres capas con categoria positiva 'SB' usando 5-fold crossvalidation obtiene una precisión de `r round(cmatrix_mlp$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_mlp$byClass["Sensitivity"], 3)` y `r round(cmatrix_mlp$byClass["Specificity"], 3)` respectivamente.  

# 7 - Comentario sobre los resultados.

Los resultados son bastante similares entre sí. Está claro que es bastante fácil conseguir una precisión alta en este caso. Me ha parecido muy interesante el sistema de validación automática de varios parámetros que he utilizado en el último caso.
Sin embargo consume mucho tiempo el probar varias combinaciones. Quise probar a hacerlo con el paquete `rpud`, pero por desgracia aún no está disponible para R 4.0.0.  
http://www.r-tutor.com/gpu-computing/rpud-installation

De forma genérica diría que para este caso se pueden obtener buenos resultados con los dos tipos de algoritmos, aunque por el tipo de problema yo me decantaría por SVN para explorar posibles optimizaciones.


Modelo | Accuracy | Kappa
--------|----------|------
Red Neuronal de 1 nodo | `r cmatrix1$overall[1]` | `r cmatrix1$overall[2]` 
Red Neuronal de 3 nodos | `r cmatrix3$overall[1]` | `r cmatrix3$overall[2]`
Multi-Layer Perceptron de 3 nodos | `r cmatrix_mlp$overall[1]` | `r cmatrix_mlp$overall[2]`
SVN Lineal | `r cmatrix_lineal$overall[1]` | `r cmatrix_lineal$overall[2]`
SVN RBF | `r cmatrix_rbf$overall[1]` | `r cmatrix_rbf$overall[2]`
SVN RBF con 5-fold cv. | `r cmatrix_rbf5f$overall[1]` | `r cmatrix_rbf5f$overall[2]`


