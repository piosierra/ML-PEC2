---
title: "PEC2- ML"
author: "Pío Alberto Sierra Rodríguez"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  pdf_document:
    toc: yes
  html_document:
    df_print: paged
    toc: yes
params:
  data_file: peptidos.csv
  training_split: 67
  seed.split: 123
  seed.clsfier: 1234567
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r include = FALSE}
if(!(require(ggseqlogo)))
  install.packages("ggseqlogo")
if(!(require(caret)))
  install.packages("caret")
if(!(require(e1071)))
  install.packages("e1071")
if(!(require(neuralnet)))
  install.packages("NeuralNetTools)")
if(!(require(NeuralNetTools)))
  install.packages("NeuralNetTools")
if(!(require(kernlab)))
  install.packages("kernlab")
if(!(require(class)))
  install.packages("class")
if(!(require(gmodels)))
  install.packages("gmodels")
if(!(require(ROCR)))
  install.packages("ROCR")
if(!(require(e1071)))
  install.packages("e1071")
```

***  
**Parámetros:**  
**data_file**: *ruta completa al archivo de péptidos*  
**training_splt**: *porcentaje a dedicar al conjunto de training [0,100]*
**transformed_file**: *archivo en el que almacenar lod datos transformados con la codificación one-hot.*
*** 

# 1- Algoritmos utilizados

## Algoritmo Red Neuronal Artificial

El algoritmo de Red Neuronal Artificial con retropropagación está inspirado en el funcionamiento de las redes neuronales biológicas, pero con un menor número de neuronas y capas. Funciona iterando repetidamente dos procesos. En uno se obtiene una salida y en otro se propaga el error de esa salida hacia atrás para corregir los pesos de de cada neurona, mediante la técnica de gradiente descendente.

Fortalezas | Debilidades
-----|------
Se puede adaptar a problemas de clasificación o predicción numéricos  | Muy costosa computacionalmente y lenta durante el aprendizaje, especialmente si la topología de la red es compleja.  
Capaz de modelizar estructuras más complejas que la mayoría de algoritmos | Es fácil caer en problemas de overfitting con esta técnica.  
Hace pocas presunciones sobre las relaciones internas de los datos | El resultado en un modelo de caja negra que es muy difícil, si no imposible, de interpretar. 

## Algoritmo Support Vector Machine

El algoritmo SVN consiste en la creacción de hiperplanos en el espacio definido por los valores de las características que creen particiones en las que clasificar los datos.  

Ventajas| Inconvenientes
-----|------
Pueden ser usados tanto para clasificación como para predicción numérica | Encontrar el mejor modelo exige probar con distintos kernels y parámetros.  
No se ve muy afectado por ruido en los datos ni es susceptible de sobreajuste. | El entrenamiento puede ser lento, sobre todo cuando se trata de datos con un gran número de características u observaciones.  
Puede resultar más sencillo de utilizar que las redes neuronales, debido a la existencia de varios algoritmos de SVN bien mantenidos. | El resultado es un complejo modelo de caja negra que resulta a menudo imposible de interpretar.  
Es bastante popular debido a su precisión y al haber resultado vencedor en varias competiciones de data mining. | -  

El algoritmo consiste en identificar los Support Vectors, las observaciones de cada clase que están más cerca del Hyperplano de margen máximo (MMH). Se demuestra que estos puntos bastan para definir el hiperplano. Para el caso de datos que no son linealmente separables, se utiliza una variable slack que define un margen al otro lado del hiperplano al que es aceptable tener alguna observación.  

Otra ventaja de SVN es la posiblidad de añadir más dimensiones a las observaciones para así hacer visibles (lineales) relaciones entre las observaciones.  

# 2 - Lectura de datos

```{r}
peptidos <- read.csv2(params$data_file)
table(peptidos$label)
ggseqlogo(peptidos[which(peptidos$label=="SB"),]$sequence)
ggseqlogo(peptidos[which(peptidos$label=="NB"),]$sequence)
```

Tenemos un `r 100*sum(peptidos$label=="SB")/length(peptidos$label)`% de peptidos con interacción.  

Podemos observar que los péptidos que tienen interacción presentan una mayor frecuencia muy marcada de aminoácidos hidrófobos en la segunda y última posición de la cadena.  

# 3 - Función de codificación "one-hot"

Implementamos una función que cree la codificación "one-hot" a partir de una cadena de aminoácidos.   
```{r}
aminoacidos <-c('A', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L',
                'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'V', 'W', 'Y')
one_hot <- function(data) {
    unlist(lapply(strsplit(data, split="")[[1]], 
                  function(x) {as.integer(aminoacidos == x)}), 
           recursive = FALSE)
}
```

# 4 - Transformación de los datos

Aplicamos ahora esa función a la lista de aminoácidos de la entrada para obtener los datos que vamos a utilizar.  
```{r}
oh_data <- data.frame(t(data.frame(lapply(peptidos$sequence, one_hot))))
```
Comprobamos que la transformación deja correctamente `r nchar(peptidos[1,1])` unos en cada fila. Y guardamos los datos.
```{r}
summary(apply(oh_data,1,sum))
write.csv2(oh_data, params$transformed_file)
# rownames(oh_data) <- peptidos$sequence  
```


# 5 - Clasificador de red neuronal artificial

## a) Lectura de los datos

Leemos los datos del archivo `r params$transformed_file`. 
```{r}
oh_data <- read.csv2(params$transformed_file)
```

## b) Preparación de datos  

Creamos variables binarias en lugar de usar la variable factor `label`.   
```{r}
oh_data$SB <- as.integer(peptidos$label=="SB")
oh_data$NB <- as.integer(peptidos$label=="NB")
n <- nrow(oh_data)
```

Ahora creamos los conjuntos entrenamiento y de prueba. Se realiza una extracción de los datos *aleatoriamente* de `r params$training_split`% de todas las observaciones, `r floor(params$training_split*n/100)`, para entrenar al modelo (training) y del resto `r n - floor(params$training_split*n/100)` para evaluarlo (test).
```{r}
set.seed(params$seed.split)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- oh_data[train_ind,]
data_test <- oh_data[-train_ind,]
```

## c,d) Entrenamiendo y predicción de modelo RNA de 1 nodo y de modelo RNA de 3 nodos

Primero creamos la fórmula a partir de los nombres de las columnas.
```{r}
xnam <- names(oh_data[1:180])
fmla <- as.formula(paste("SB+NB ~ ", paste(xnam, collapse= "+")))
```
Creamos los modelos reseteando la semilla antes de cada uno al valor `params$seed.clsfier`.  
```{r}
set.seed(params$seed.clsfier)
data_model_1 <- neuralnet(fmla,
                          data = data_train,
                          hidden=1,linear.output=FALSE)
set.seed(params$seed.clsfier)
data_model_3 <- neuralnet(fmla,
                          data = data_train,
                          hidden=3,linear.output=FALSE)

```

Mostramos las redes resultantes de cada modelo.  

```{r}
plot(data_model_1, rep='best')
plot(data_model_3, rep='best')

```

Obtenemos las predicciones y convertimos la salida numérica binaria (probabilidades) en una categórica para comparar los resultados.

```{r}

model_results_1 <- compute(data_model_1, data_test[,1:180])$net.result
model_results_3 <- compute(data_model_3, data_test[,1:180])$net.result

maxidx <- function(arr) {
  return(which(arr == max(arr)))
}

idx1 <- apply(model_results_1, 1, maxidx)
idx3 <- apply(model_results_3, 1, maxidx)
prediction1 <- c('SB', 'NB')[idx1]
prediction3 <- c('SB', 'NB')[idx3]
res1 <- table(prediction1, peptidos$label[-train_ind] )
res3 <- table(prediction3, peptidos$label[-train_ind] )

```

## e) Resultados de la clasificación.

```{r}
(cmatrix1 <- caret::confusionMatrix(res1,positive="SB"))
(cmatrix3 <- caret::confusionMatrix(res3,positive="SB"))
```

El modelo de una capa con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix1$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix1$byClass["Sensitivity"], 3)` y `r round(cmatrix1$byClass["Specificity"], 3)` respectivamente.  
El modelo de tres capas con categoria positiva 'SB' obtiene una precisión de `r round(cmatrix3$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix3$byClass["Sensitivity"], 3)` y `r round(cmatrix3$byClass["Specificity"], 3)` respectivamente.  
`r if(cmatrix1$overall["Accuracy"] > cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con un solo nodo tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] < cmatrix3$overall["Accuracy"]){"Vemos que el modelo obtenido con tres nodos tiene una mayor precisión"}``r if(cmatrix1$overall["Accuracy"] == cmatrix3$overall["Accuracy"]){"Vemos que ambos modelos tienen la misma precisión"}`

## f) Modelo `mlp` de 3 nodos con 5-fold crossvalidation.

Ahora utilizamos el paquete `caret` para entrenar un modelo Multi-Layer Perceptron. Para detallar que es de tres nodos tenemos que incluir un data.frame en la variable `tuneGrid` de `train` con los parámetros necesarios para el modelo, en este caso `size`, como columnas con el nombre del parámetro empezando por ".".  

```{r}
set.seed(params$seed.clsfier)
data.frame(.size=3)
model <- caret::train(data_train[,1:180], as.factor(peptidos$label[train_ind]), method='mlp', 
               trControl= trainControl(method='cv', number=5), 
               tuneGrid= data.frame(.size=3), tuneLength=10 ,trace = FALSE)
prediction <- predict(model, data_test) 
res <- table(prediction, peptidos$label[-train_ind] )
(cmatrix_mlp <- caret::confusionMatrix(res,positive="SB"))
```

El modelo `mlp` de tres capas con categoria positiva 'SB' usando 5-fold crossvalidation obtiene una precisión de `r round(cmatrix_mlp$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_mlp$byClass["Sensitivity"], 3)` y `r round(cmatrix_mlp$byClass["Specificity"], 3)` respectivamente.  

# 6 - Implementación de un clasificador de SVN

## a) Preparación de datos  

Leemos los datos del archivo `r params$transformed_file`.   
```{r}
oh_data <- read.csv2(params$transformed_file)
```

## b) Preparación de datos  

Para SVN vamos a utilizar como resultado la variable `label` original, sin necesidad de convertirla a un valor numérico como hicimos para la red neuronal.  

```{r}
set.seed(params$seed.split)
data_svn <- oh_data[,1:180]
data_svn$label <- as.factor(peptidos$label)
smp_size <-  floor(n * params$training_split/100)
train_ind <- sample(seq_len(n), size = smp_size)
data_train <- data_svn[train_ind,]
data_test <- data_svn[-train_ind,]
```
## c,d) Entrenamiendo y predicción de modelos SVN lineal y RBF  

Creamos los modelos reseteando la semilla antes de cada uno al valor `params$seed.clsfier`.  

```{r}
# Modelo lineal
set.seed(params$seed.clsfier)
(modeloLineal <- ksvm(label~.,data=data_train, kernel='vanilladot'))
modLineal_pred <- predict(modeloLineal, data_test)
res_lineal <- table(modLineal_pred, data_test$label)
# Modelo RBF
set.seed(params$seed.clsfier)
(modeloGauss <- ksvm(label~.,data=data_train, kernel='rbfdot'))
modGauss_pred <- predict(modeloGauss, data_test)
res_rbf <- table(modGauss_pred, data_test$label)

```


## e) Resultados de la clasificación.

```{r}
(cmatrix_lineal <- caret::confusionMatrix(res_lineal, positive="SB"))
(cmatrix_rbf <- caret::confusionMatrix(res_rbf, positive="SB"))
```

El modelo SVN lineal con categoría positiva 'SB' obtiene una precisión de `r round(cmatrix_lineal$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_lineal$byClass["Sensitivity"], 3)` y `r round(cmatrix_lineal$byClass["Specificity"], 3)` respectivamente.  

El modelo SVN RBF con categoría positiva 'SB' obtiene una precisión de `r round(cmatrix_rbf$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_rbf$byClass["Sensitivity"], 3)` y `r round(cmatrix_rbf$byClass["Specificity"], 3)` respectivamente.  

`r if(cmatrix_lineal$overall["Accuracy"] > cmatrix_rbf$overall["Accuracy"]){"Vemos que el modelo SVN lineal tiene una mayor precisión"}``r if(cmatrix_lineal$overall["Accuracy"] < cmatrix_rbf$overall["Accuracy"]){"Vemos que el modelo SVN RBF tiene una mayor precisión"}``r if(cmatrix_lineal$overall["Accuracy"] == cmatrix_rbf$overall["Accuracy"]){"Vemos que ambos modelos tienen la misma precisión"}`

## f) Modelo SVN RBF del paquete `caret` con 5-fold crossvalidation.

Ahora utilizamos el paquete `caret` para entrenar un modelo SVN con el método `svmRadial`. Para detallar que es de tres nodos tenemos que incluir un data.frame en la variable `tuneGrid` de `train` con los parámetros necesarios para el modelo, en este caso `sigma` y `C`, como columnas con el nombre del parámetro empezando por ".".  
En este caso optamos por probar con varias combinaciones de los parámetros y escoger la mejor en función de la precisión.  


```{r}
svmGrid <- expand.grid(sigma= 2^c(-10,-8), C= 2^c(0,1))
set.seed(params$seed.clsfier)
model <- caret::train(label~., data= data_train, method='svmRadial', 
               trControl= trainControl(method='cv', number=5, classProbs = TRUE), 
                tuneGrid= svmGrid, metric = "Accuracy",trace = FALSE)
model
prediction <- predict(model, data_test)                           # predict
res <- table(prediction, data_test$label)                             # compare

caret::confusionMatrix(res, positive="SB")  

```
El modelo `mlp` de tres capas con categoria positiva 'SB' usando 5-fold crossvalidation obtiene una precisión de `r round(cmatrix_mlp$overall["Accuracy"], 3)` y una sensitividad y especificidad de `r round(cmatrix_mlp$byClass["Sensitivity"], 3)` y `r round(cmatrix_mlp$byClass["Specificity"], 3)` respectivamente.  
